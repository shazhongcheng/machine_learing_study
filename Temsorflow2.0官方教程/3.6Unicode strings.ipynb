{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä»‹ç»\n",
    "\n",
    "å¤„ç†è‡ªç„¶è¯­è¨€çš„æ¨¡å‹é€šå¸¸ä½¿ç”¨ä¸åŒçš„å­—ç¬¦é›†æ¥å¤„ç†ä¸åŒçš„è¯­è¨€ã€‚ Unicodeæ˜¯ä¸€ç§æ ‡å‡†çš„ç¼–ç ç³»ç»Ÿï¼Œç”¨äºè¡¨ç¤ºå‡ ä¹æ‰€æœ‰è¯­è¨€çš„å­—ç¬¦ã€‚æ¯ä¸ªå­—ç¬¦ä½¿ç”¨å’Œä¹‹é—´çš„å”¯ä¸€æ•´æ•°ä»£ç ç‚¹ç¼–ç ã€‚ç”²Unicodeå­—ç¬¦ä¸²æ˜¯é›¶ä¸ªæˆ–æ›´å¤šä¸ªç ç‚¹çš„åºåˆ—ã€‚00x10FFFF\n",
    "\n",
    "æœ¬æ•™ç¨‹ä»‹ç»äº†å¦‚ä½•åœ¨TensorFlowä¸­è¡¨ç¤ºUnicodeå­—ç¬¦ä¸²ï¼Œä»¥åŠå¦‚ä½•ä½¿ç”¨ä¸æ ‡å‡†å­—ç¬¦ä¸²opsç­‰æ•ˆçš„Unicodeè¿›è¡Œæ“ä½œã€‚å®ƒå°†åŸºäºè„šæœ¬æ£€æµ‹å°†Unicodeå­—ç¬¦ä¸²åˆ†æˆä»¤ç‰Œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ã€é»˜è®¤çš„tensorflowå­—ç¬¦ä¸²å¸¸é‡é»˜è®¤ä¸ºutf-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¯¥tf.stringæ•°æ®ç±»å‹\n",
    "\n",
    "åŸºæœ¬çš„TensorFlow å…è®¸æ‚¨æ„å»ºå­—èŠ‚ä¸²çš„å¼ é‡ã€‚Unicodeå­—ç¬¦ä¸²é»˜è®¤ä¸ºutf-8ç¼–ç ã€‚tf.string dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=0, shape=(), dtype=string, numpy=b'Thanks \\xf0\\x9f\\x98\\x8a'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(u\"Thanks ğŸ˜Š\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸€ä¸ªtf.stringå¼ é‡å¯å®¹çº³ä¸åŒé•¿åº¦çš„å­—èŠ‚ä¸²ï¼Œå› ä¸ºå­—èŠ‚ä¸²ä½œä¸ºåŸå­å•ä½å¤„ç†ã€‚å¼ é‡å°ºå¯¸ä¸­ä¸åŒ…æ‹¬å­—ç¬¦ä¸²é•¿åº¦ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([u\"You're\", u\"welcome!\"]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ã€ä¸åŒçš„ç¼–ç æ ¼å¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¡¨ç¤ºUnicode\n",
    "åœ¨TensorFlowä¸­æœ‰ä¸¤ç§è¡¨ç¤ºUnicodeå­—ç¬¦ä¸²çš„æ ‡å‡†æ–¹æ³•ï¼š\n",
    "\n",
    "* stringæ ‡é‡â€”ä½¿ç”¨å·²çŸ¥çš„å­—ç¬¦ç¼–ç å¯¹ä»£ç ç‚¹åºåˆ—è¿›è¡Œç¼–ç ã€‚\n",
    "* int32 å‘é‡-æ¯ä¸ªä½ç½®éƒ½åŒ…å«ä¸€ä¸ªä»£ç ç‚¹ã€‚\n",
    "\n",
    "ä¾‹å¦‚ï¼Œä»¥ä¸‹ä¸‰ä¸ªå€¼å‡è¡¨ç¤ºUnicodeå­—ç¬¦ä¸²\"è¯­è¨€å¤„ç†\"ï¼ˆåœ¨ä¸­æ–‡ä¸­è¡¨ç¤ºâ€œè¯­è¨€å¤„ç†â€ï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2, shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-8 encoded string scalar.\n",
    "text_utf8 = tf.constant(u\"è¯­è¨€å¤„ç†\")\n",
    "text_utf8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=3, shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a UTF-16-BE encoded string scalar.\n",
    "text_utf16be = tf.constant(u\"è¯­è¨€å¤„ç†\".encode(\"UTF-16-BE\"))\n",
    "text_utf16be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4, shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unicode string, represented as a vector of Unicode code points.\n",
    "text_chars = tf.constant([ord(char) for char in u\"è¯­è¨€å¤„ç†\"])\n",
    "text_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ã€ä¸åŒç¼–ç æ ¼å¼ä¹‹é—´çš„è½¬æ¢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨åˆ¶å›¾è¡¨è¾¾ä¹‹é—´è½¬æ¢\n",
    "TensorFlowæä¾›äº†åœ¨è¿™äº›ä¸åŒè¡¨ç¤ºä¹‹é—´è¿›è¡Œè½¬æ¢çš„æ“ä½œï¼š\n",
    "\n",
    "* tf.strings.unicode_decodeï¼šå°†ç¼–ç çš„å­—ç¬¦ä¸²æ ‡é‡è½¬æ¢ä¸ºä»£ç ç‚¹çš„å‘é‡ã€‚\n",
    "* tf.strings.unicode_encodeï¼šå°†ä»£ç ç‚¹çš„å‘é‡è½¬æ¢ä¸ºç¼–ç çš„å­—ç¬¦ä¸²æ ‡é‡ã€‚\n",
    "* tf.strings.unicode_transcodeï¼šå°†ç¼–ç çš„å­—ç¬¦ä¸²æ ‡é‡è½¬æ¢ä¸ºå…¶ä»–ç¼–ç ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=8, shape=(4,), dtype=int32, numpy=array([35821, 35328, 22788, 29702])>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(text_utf8,\n",
    "                          input_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=18, shape=(), dtype=string, numpy=b'\\xe8\\xaf\\xad\\xe8\\xa8\\x80\\xe5\\xa4\\x84\\xe7\\x90\\x86'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(text_chars,\n",
    "                          output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=19, shape=(), dtype=string, numpy=b'\\x8b\\xed\\x8a\\x00Y\\x04t\\x06'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_transcode(text_utf8,\n",
    "                             input_encoding='UTF8',\n",
    "                             output_encoding='UTF-16-BE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ã€æŒ‰æ‰¹æ¬¡ç¼–ç "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‰¹æ¬¡å°ºå¯¸\n",
    "\n",
    "è§£ç å¤šä¸ªå­—ç¬¦ä¸²æ—¶ï¼Œæ¯ä¸ªå­—ç¬¦ä¸²ä¸­çš„å­—ç¬¦æ•°å¯èƒ½ä¸ç›¸ç­‰ã€‚è¿”å›ç»“æœæ˜¯a tf.RaggedTensorï¼Œå…¶ä¸­æœ€é‡Œé¢çš„ç»´çš„é•¿åº¦æ ¹æ®æ¯ä¸ªå­—ç¬¦ä¸²ä¸­çš„å­—ç¬¦æ•°è€Œå˜åŒ–ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104, 195, 108, 108, 111]\n",
      "[87, 104, 97, 116, 32, 105, 115, 32, 116, 104, 101, 32, 119, 101, 97, 116, 104, 101, 114, 32, 116, 111, 109, 111, 114, 114, 111, 119]\n",
      "[71, 246, 246, 100, 110, 105, 103, 104, 116]\n",
      "[128522]\n"
     ]
    }
   ],
   "source": [
    "# A batch of Unicode strings, each represented as a UTF8-encoded string.\n",
    "batch_utf8 = [s.encode('UTF-8') for s in\n",
    "              [u'hÃƒllo',  u'What is the weather tomorrow',  u'GÃ¶Ã¶dnight', u'ğŸ˜Š']]\n",
    "batch_chars_ragged = tf.strings.unicode_decode(batch_utf8,\n",
    "                                               input_encoding='UTF-8')\n",
    "for sentence_chars in batch_chars_ragged.to_list():\n",
    "    print(sentence_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‚¨å¯ä»¥tf.RaggedTensorç›´æ¥ä½¿ç”¨æ­¤æ ¼å¼ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨tf.Tensorpaddingæˆ–tf.SparseTensorä½¿ç”¨æ–¹æ³•tf.RaggedTensor.to_tensorå’Œå°†å…¶è½¬æ¢ä¸ºå¯†é›†æ ¼å¼tf.RaggedTensor.to_sparseã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### å®šé•¿å¡«å……"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   104    195    108    108    111     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [    87    104     97    116     32    105    115     32    116    104\n",
      "     101     32    119    101     97    116    104    101    114     32\n",
      "     116    111    109    111    114    114    111    119]\n",
      " [    71    246    246    100    110    105    103    104    116     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]\n",
      " [128522     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1     -1     -1\n",
      "      -1     -1     -1     -1     -1     -1     -1     -1]]\n"
     ]
    }
   ],
   "source": [
    "batch_chars_padded = batch_chars_ragged.to_tensor(default_value=-1)\n",
    "print(batch_chars_padded.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 28)\n"
     ]
    }
   ],
   "source": [
    "print(batch_chars_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[ 0  0]\n",
      " [ 0  1]\n",
      " [ 0  2]\n",
      " [ 0  3]\n",
      " [ 0  4]\n",
      " [ 1  0]\n",
      " [ 1  1]\n",
      " [ 1  2]\n",
      " [ 1  3]\n",
      " [ 1  4]\n",
      " [ 1  5]\n",
      " [ 1  6]\n",
      " [ 1  7]\n",
      " [ 1  8]\n",
      " [ 1  9]\n",
      " [ 1 10]\n",
      " [ 1 11]\n",
      " [ 1 12]\n",
      " [ 1 13]\n",
      " [ 1 14]\n",
      " [ 1 15]\n",
      " [ 1 16]\n",
      " [ 1 17]\n",
      " [ 1 18]\n",
      " [ 1 19]\n",
      " [ 1 20]\n",
      " [ 1 21]\n",
      " [ 1 22]\n",
      " [ 1 23]\n",
      " [ 1 24]\n",
      " [ 1 25]\n",
      " [ 1 26]\n",
      " [ 1 27]\n",
      " [ 2  0]\n",
      " [ 2  1]\n",
      " [ 2  2]\n",
      " [ 2  3]\n",
      " [ 2  4]\n",
      " [ 2  5]\n",
      " [ 2  6]\n",
      " [ 2  7]\n",
      " [ 2  8]\n",
      " [ 3  0]], shape=(43, 2), dtype=int64), values=tf.Tensor(\n",
      "[   104    195    108    108    111     87    104     97    116     32\n",
      "    105    115     32    116    104    101     32    119    101     97\n",
      "    116    104    101    114     32    116    111    109    111    114\n",
      "    114    111    119     71    246    246    100    110    105    103\n",
      "    104    116 128522], shape=(43,), dtype=int32), dense_shape=tf.Tensor([ 4 28], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "batch_chars_sparse = batch_chars_ragged.to_sparse()\n",
    "print(batch_chars_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 28)\n"
     ]
    }
   ],
   "source": [
    "print(batch_chars_sparse.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ã€è§£ç "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "åœ¨å¯¹å¤šä¸ªå…·æœ‰ç›¸åŒé•¿åº¦çš„å­—ç¬¦ä¸²è¿›è¡Œç¼–ç æ—¶ï¼Œå¯ä»¥å°†ä¸€ä¸ªtf.Tensorç”¨ä½œè¾“å…¥ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=119, shape=(3,), dtype=string, numpy=array([b'cat', b'dog', b'cow'], dtype=object)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode([[99, 97, 116], [100, 111, 103], [ 99, 111, 119]],\n",
    "                          output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¯¹é•¿åº¦å¯å˜çš„å¤šä¸ªå­—ç¬¦ä¸²è¿›è¡Œç¼–ç æ—¶ï¼Œåº”å°†ä¸€ä¸ªtf.RaggedTensorç”¨ä½œè¾“å…¥ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=120, shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(batch_chars_ragged, output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¦‚æœæ‚¨çš„å¼ é‡å…·æœ‰å¡«å……æˆ–ç¨€ç–æ ¼å¼çš„å¤šä¸ªå­—ç¬¦ä¸²ï¼Œè¯·tf.RaggedTensoråœ¨è°ƒç”¨ä¹‹å‰å°†å…¶è½¬æ¢ä¸ºunicode_encodeï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=199, shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_sparse(batch_chars_sparse),\n",
    "    output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=272, shape=(4,), dtype=string, numpy=\n",
       "array([b'h\\xc3\\x83llo', b'What is the weather tomorrow',\n",
       "       b'G\\xc3\\xb6\\xc3\\xb6dnight', b'\\xf0\\x9f\\x98\\x8a'], dtype=object)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(\n",
    "    tf.RaggedTensor.from_tensor(batch_chars_padded, padding=-1),\n",
    "    output_encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ã€é•¿åº¦ç›¸å…³"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unicodeæ“ä½œ\n",
    "\n",
    "å­—ç¬¦é•¿åº¦\n",
    "\n",
    "è¯¥tf.strings.lengthæ“ä½œå…·æœ‰ä¸€ä¸ªå‚æ•°unitï¼Œè¯¥å‚æ•°æŒ‡ç¤ºåº”å¦‚ä½•è®¡ç®—é•¿åº¦ã€‚ unité»˜è®¤ä¸º\"BYTE\"ï¼Œä½†æ˜¯å¯ä»¥å°†å…¶è®¾ç½®ä¸ºå…¶ä»–å€¼ï¼Œä¾‹å¦‚\"UTF8_CHAR\"æˆ–\"UTF16_CHAR\"ï¼Œä»¥ç¡®å®šæ¯ä¸ªå·²ç¼–ç çš„Unicodeä»£ç ç‚¹çš„æ•°é‡stringã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 bytes; 8 UTF-8 characters\n"
     ]
    }
   ],
   "source": [
    "# Note that the final character takes up 4 bytes in UTF8.\n",
    "thanks = u'Thanks ğŸ˜Š'.encode('UTF-8')\n",
    "num_bytes = tf.strings.length(thanks).numpy()\n",
    "num_chars = tf.strings.length(thanks, unit='UTF8_CHAR').numpy()\n",
    "print('{} bytes; {} UTF-8 characters'.format(num_bytes, num_chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å­—ç¬¦å­ä¸²\n",
    "\n",
    "ç±»ä¼¼åœ°ï¼Œè¯¥tf.strings.substræ“ä½œæ¥å—â€œ unitâ€å‚æ•°ï¼Œå¹¶ä½¿ç”¨å®ƒæ¥ç¡®å®šâ€œ posâ€å’Œâ€œ lenâ€å‚æ•°åŒ…å«çš„åç§»é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xf0'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# default: unit='BYTE'. With len=1, we return a single byte.\n",
    "tf.strings.substr(thanks, pos=7, len=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\xf0\\x9f\\x98\\x8a'\n"
     ]
    }
   ],
   "source": [
    "# Specifying unit='UTF8_CHAR', we return a single character, which in this case\n",
    "# is 4 bytes.\n",
    "print(tf.strings.substr(thanks, pos=7, len=1, unit='UTF8_CHAR').numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‹†åˆ†Unicodeå­—ç¬¦ä¸²\n",
    "\n",
    "è¯¥tf.strings.unicode_splitæ“ä½œå°†unicodeå­—ç¬¦ä¸²æ‹†åˆ†ä¸ºå„ä¸ªå­—ç¬¦çš„å­å­—ç¬¦ä¸²ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'T', b'h', b'a', b'n', b'k', b's', b' ', b'\\xf0\\x9f\\x98\\x8a'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_split(thanks, 'UTF-8').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ã€å­—ç¬¦çš„å­—èŠ‚åç§»\n",
    "\n",
    "ä¸ºäº†å°†ç”Ÿæˆçš„å­—ç¬¦å¼ é‡tf.strings.unicode_decodeä¸åŸå§‹å­—ç¬¦ä¸²å¯¹é½ï¼Œäº†è§£æ¯ä¸ªå­—ç¬¦å¼€å§‹ä½ç½®çš„åç§»é‡å¾ˆæœ‰ç”¨ã€‚è¯¥æ–¹æ³•tf.strings.unicode_decode_with_offsetsç±»ä¼¼äºunicode_decodeï¼Œé™¤äº†å®ƒè¿”å›åŒ…å«æ¯ä¸ªå­—ç¬¦çš„èµ·å§‹åç§»é‡çš„ç¬¬äºŒå¼ é‡ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At byte offset 0: codepoint 127880\n",
      "At byte offset 4: codepoint 127881\n",
      "At byte offset 8: codepoint 127882\n"
     ]
    }
   ],
   "source": [
    "codepoints, offsets = tf.strings.unicode_decode_with_offsets(u\"ğŸˆğŸ‰ğŸŠ\", 'UTF-8')\n",
    "\n",
    "for (codepoint, offset) in zip(codepoints.numpy(), offsets.numpy()):\n",
    "    print(\"At byte offset {}: codepoint {}\".format(offset, codepoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ã€è·å–ç¼–ç ä½¿ç”¨å“ªä¸ªè„šæœ¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unicodeè„šæœ¬\n",
    "\n",
    "æ¯ä¸ªUnicodeä»£ç ç‚¹éƒ½å±äºä¸€ä¸ªç§°ä¸ºè„šæœ¬çš„ä»£ç ç‚¹çš„å•ä¸ªé›†åˆã€‚è§’è‰²çš„è„šæœ¬æœ‰åŠ©äºç¡®å®šè§’è‰²å¯èƒ½ä½¿ç”¨çš„è¯­è¨€ã€‚ä¾‹å¦‚ï¼ŒçŸ¥é“è¥¿é‡Œå°”å­—æ¯ä¸­çš„'Ğ‘'è¡¨ç¤ºè¯¥åŒ…å«è¯¥è§’è‰²çš„ç°ä»£æ–‡æœ¬å¾ˆå¯èƒ½æ¥è‡ªæ–¯æ‹‰å¤«è¯­ï¼Œä¾‹å¦‚ä¿„è¯­æˆ–ä¹Œå…‹å…°è¯­ã€‚\n",
    "\n",
    "TensorFlowæä¾›äº†tf.strings.unicode_scriptç¡®å®šç»™å®šä»£ç ç‚¹ä½¿ç”¨å“ªä¸ªè„šæœ¬çš„æ“ä½œã€‚è„šæœ¬ä»£ç æ˜¯int32ä¸Unicodeå›½é™…ç»„ä»¶ï¼ˆICUï¼‰UScriptCodeå€¼ç›¸å¯¹åº”çš„å€¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  8]\n"
     ]
    }
   ],
   "source": [
    "uscript = tf.strings.unicode_script([33464, 1041])  # ['èŠ¸', 'Ğ‘']\n",
    "\n",
    "print(uscript.numpy())  # [17, 8] == [USCRIPT_HAN, USCRIPT_CYRILLIC]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[25, 25, 25, 25, 25], [25, 25, 25, 25, 0, 25, 25, 0, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 0, 25, 25, 25, 25, 25, 25, 25, 25], [25, 25, 25, 25, 25, 25, 25, 25, 25], [0]]>\n"
     ]
    }
   ],
   "source": [
    "print(tf.strings.unicode_script(batch_chars_ragged))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç¤ºä¾‹ï¼šç®€å•ç»†åˆ†\n",
    "\n",
    "åˆ†æ®µæ˜¯å°†æ–‡æœ¬æ‹†åˆ†ä¸ºç±»ä¼¼å•è¯çš„å•å…ƒçš„ä»»åŠ¡ã€‚å½“ä½¿ç”¨ç©ºæ ¼å­—ç¬¦åˆ†éš”å•è¯æ—¶ï¼Œè¿™é€šå¸¸å¾ˆå®¹æ˜“ï¼Œä½†æ˜¯æŸäº›è¯­è¨€ï¼ˆå¦‚ä¸­æ–‡å’Œæ—¥è¯­ï¼‰ä¸ä½¿ç”¨ç©ºæ ¼ï¼Œè€ŒæŸäº›è¯­è¨€ï¼ˆå¦‚å¾·è¯­ï¼‰åŒ…å«å¿…é¡»åˆ†è§£ä»¥åˆ†æå…¶å«ä¹‰çš„é•¿åŒ–åˆç‰©ã€‚åœ¨Webæ–‡æœ¬ä¸­ï¼Œç»å¸¸å°†ä¸åŒçš„è¯­è¨€å’Œè„šæœ¬æ··åˆåœ¨ä¸€èµ·ï¼Œä¾‹å¦‚â€œ NYæ ªä¾¡â€ï¼ˆçº½çº¦è¯åˆ¸äº¤æ˜“æ‰€ï¼‰ã€‚\n",
    "\n",
    "é€šè¿‡ä½¿ç”¨è„šæœ¬ä¸­çš„æ›´æ”¹æ¥è¿‘ä¼¼å•è¯è¾¹ç•Œï¼Œæˆ‘ä»¬å¯ä»¥æ‰§è¡Œéå¸¸ç²—ç•¥çš„ç»†åˆ†ï¼ˆæ— éœ€å®ç°ä»»ä½•MLæ¨¡å‹ï¼‰ã€‚è¿™å°†é€‚ç”¨äºä¸Šé¢çš„â€œ NYæ ªä¾¡â€ç¤ºä¾‹ä¹‹ç±»çš„å­—ç¬¦ä¸²ã€‚å®ƒä¹Ÿé€‚ç”¨äºå¤§å¤šæ•°ä½¿ç”¨ç©ºæ ¼çš„è¯­è¨€ï¼Œå› ä¸ºå„ç§è„šæœ¬çš„ç©ºæ ¼å­—ç¬¦éƒ½å½’ç±»ä¸ºUSCRIPT_COMMONï¼Œè¿™æ˜¯ä¸€ç§ç‰¹æ®Šçš„è„šæœ¬ä»£ç ï¼Œä¸åŒäºä»»ä½•å®é™…çš„æ–‡æœ¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype: string; shape: [num_sentences]\n",
    "#\n",
    "# The sentences to process.  Edit this line to try out different inputs!\n",
    "sentence_texts = [u'Hello, world.', u'ä¸–ç•Œã“ã‚“ã«ã¡ã¯']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "é¦–å…ˆï¼Œæˆ‘ä»¬å°†å¥å­è§£ç ä¸ºå­—ç¬¦ä»£ç ç‚¹ï¼Œç„¶åä¸ºæ¯ä¸ªå­—ç¬¦æ‰¾åˆ°è„šæœ¬æ ‡è¯†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111, 44, 32, 119, 111, 114, 108, 100, 46], [19990, 30028, 12371, 12435, 12395, 12385, 12399]]>\n",
      "<tf.RaggedTensor [[25, 25, 25, 25, 25, 0, 0, 25, 25, 25, 25, 25, 0], [17, 17, 20, 20, 20, 20, 20]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_codepoint[i, j] is the codepoint for the j'th character in\n",
    "# the i'th sentence.\n",
    "sentence_char_codepoint = tf.strings.unicode_decode(sentence_texts, 'UTF-8')\n",
    "print(sentence_char_codepoint)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_scripts[i, j] is the unicode script of the j'th character in\n",
    "# the i'th sentence.\n",
    "sentence_char_script = tf.strings.unicode_script(sentence_char_codepoint)\n",
    "print(sentence_char_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ã€æ ¹æ®è„šæœ¬æ ‡è¯†ç¡®è®¤å•è¯è¾¹ç•Œçš„ä¾‹å­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨è¿™äº›è„šæœ¬æ ‡è¯†ç¬¦æ¥ç¡®å®šåº”åœ¨ä½•å¤„æ·»åŠ å•è¯è¾¹ç•Œã€‚æˆ‘ä»¬åœ¨æ¯ä¸ªå¥å­çš„å¼€å¤´ä»¥åŠè„šæœ¬ä¸ä¸Šä¸€ä¸ªå­—ç¬¦ä¸åŒçš„æ¯ä¸ªå­—ç¬¦å¤„æ·»åŠ å•è¯è¾¹ç•Œï¼š"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è®¡ç®—ä¸ä¸€æ ·çš„è¾¹ç•Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  5  7 12 13 15], shape=(6,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# dtype: bool; shape: [num_sentences, (num_chars_per_sentence)]\n",
    "#\n",
    "# sentence_char_starts_word[i, j] is True if the j'th character in the i'th\n",
    "# sentence is the start of a word.\n",
    "sentence_char_starts_word = tf.concat(\n",
    "    [tf.fill([sentence_char_script.nrows(), 1], True),\n",
    "     tf.not_equal(sentence_char_script[:, 1:], sentence_char_script[:, :-1])],\n",
    "    axis=1)\n",
    "\n",
    "# dtype: int64; shape: [num_words]\n",
    "#\n",
    "# word_starts[i] is the index of the character that starts the i'th word (in\n",
    "# the flattened list of characters from all sentences).\n",
    "word_starts = tf.squeeze(tf.where(sentence_char_starts_word.values), axis=1)\n",
    "print(word_starts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆ‡åˆ†å¥å­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™äº›èµ·å§‹åç§»é‡æ¥æ„å»ºä¸€ä¸ªRaggedTensoråŒ…å«æ‰€æœ‰æ‰¹æ¬¡çš„å•è¯åˆ—è¡¨çš„ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46], [19990, 30028], [12371, 12435, 12395, 12385, 12399]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int32; shape: [num_words, (num_chars_per_word)]\n",
    "#\n",
    "# word_char_codepoint[i, j] is the codepoint for the j'th character in the\n",
    "# i'th word.\n",
    "word_char_codepoint = tf.RaggedTensor.from_row_starts(\n",
    "    values=sentence_char_codepoint.values,\n",
    "    row_starts=word_starts)\n",
    "print(word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åˆå¹¶å¥å­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æœ€åï¼Œæˆ‘ä»¬å¯ä»¥å°†ä»£ç ç‚¹è¿™ä¸ªè¯ç»†åˆ†RaggedTensorä¸ºå¥å­ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[[72, 101, 108, 108, 111], [44, 32], [119, 111, 114, 108, 100], [46]], [[19990, 30028], [12371, 12435, 12395, 12385, 12399]]]>\n"
     ]
    }
   ],
   "source": [
    "# dtype: int64; shape: [num_sentences]\n",
    "#\n",
    "# sentence_num_words[i] is the number of words in the i'th sentence.\n",
    "sentence_num_words = tf.reduce_sum(\n",
    "    tf.cast(sentence_char_starts_word, tf.int64),\n",
    "    axis=1)\n",
    "\n",
    "# dtype: int32; shape: [num_sentences, (num_words_per_sentence), (num_chars_per_word)]\n",
    "#\n",
    "# sentence_word_char_codepoint[i, j, k] is the codepoint for the k'th character\n",
    "# in the j'th word in the i'th sentence.\n",
    "sentence_word_char_codepoint = tf.RaggedTensor.from_row_lengths(\n",
    "    values=word_char_codepoint,\n",
    "    row_lengths=sentence_num_words)\n",
    "print(sentence_word_char_codepoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### è½¬å›"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ºäº†ä½¿æœ€ç»ˆç»“æœæ›´æ˜“äºé˜…è¯»ï¼Œæˆ‘ä»¬å¯ä»¥å°†å…¶ç¼–ç å›UTF-8å­—ç¬¦ä¸²ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[b'Hello', b', ', b'world', b'.'],\n",
       " [b'\\xe4\\xb8\\x96\\xe7\\x95\\x8c',\n",
       "  b'\\xe3\\x81\\x93\\xe3\\x82\\x93\\xe3\\x81\\xab\\xe3\\x81\\xa1\\xe3\\x81\\xaf']]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_encode(sentence_word_char_codepoint, 'UTF-8').to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
